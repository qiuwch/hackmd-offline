# TODO: Active Vision - CVPR draft

Title: Active selection of training data from virtual worlds

## Introduction

Training data is important for machine learning and computer vision. High capacity models enable us to do use much more data then before. Researchers spent great effort from creating large nubmer dataset\cite{}, but data is still not enough. 

Synthetic data is a solution for solving this bottleneck of data limiation. Researchers\cite{Suhao,sintel,stereo} showed that using synthetic data can help the performance on real data. Many methods for creating synthetic data have been proposed. Using synthetic data, it is easier to get large amount of images and videos with detailed annotation. Large scale 3D model repository\cite{shapenet} made the virtual environment rich. It is easy to generate millions of images with different rendering configurations.

Previously, all the training data of an image dataset will be used to train an algorithm, because the limited number of images, data augmentation needs to be done to enrich the variety of the dataset. But this is no longer true for a synthetic dataset. For a synthetic dataset, the number of images is theroretically infinite. \cite{synthesia,sintel,suhao} sampled some images from the virtual environment by controlling the virtual camera. But these images are only a small portition of the virtual world, more images can be produced by tweak the parameters of objects. It would be better if we can use all the images generated by a virtual environment. But this is not possible, given the limited number of memory and disk. It is also inefficient to feed these large amount of data to an algorithm. Many data might be just too easy or not representative enough, so that training time is wasted.

In this paper, we developed an algorithm to allow us to automatically explore the virtual world and pick the most useful training examples. Using this technique, we can explore a larger portion of the virtual world and we can achieve better result given the same training data. We used the object pose algorithm[maybe mor] to demonstrate the effectiveness of our method. 

## Related work

Render for CNN
OHEM
Never forgetting learning.



